Grammar:

	module
		stat-list
	
	stat-list
		stat stat-list

	stat
		if-stat
		for-in-stat
		var-decl
		assign-stat
		exp

	if-stat
		if-block
		if-block else-block
		
		if-block
			'if' exp block
		else-block
			'else' if-stat // chained else-if here
			'else' block   // terminating else

	for-in-stat
		'for' ident 'in' exp block
	
	block
		'{' stat-list '}'
	
	var-decl
		'let' ident '=' exp

	assign-stat
		locator '=' exp

	locator
		access-exp
		index-exp
		primary-exp

	exp:
		ternary-exp
			binary-exp '?' ternary-exp ':' ternary-exp
			binary-exp

	binary-exp
			or-exp		and-exp [ || or-exp ]			// left-assoc because of short circuiting
			and-exp		bit-or-exp [ && and-exp ]		// left-assoc because of short circuiting

			bit-or-exp	bit-xor-exp [ | bit-or-exp ]	// left assoc
			bit-xor-exp	bit-and-exp [ ^ bit-xor-exp ]	// associative
			bit-and-exp cmp-exp [ & bit-and-exp ]		// associative

			cmp-exp		shl-exp [ cmp-op cmp-exp ]		// TODO: don't allow chained comparisons a == b == c

			shl-exp		shr-exp [ << shl-exp ]			// left associative
			shr-exp		add-exp [ >> adr-exp ]			// left associative

			add-exp		sub-exp [ + add-exp ]			// associative
			sub-exp		mul-exp	[ - sub-exp ]			// left associative
			mul-exp		div-exp [ * mul-exp ]			// associative
			div-exp		mod-exp [ / div-exp ]			// left associative
			mod-exp		pow-exp [ % mod-exp ]			// left associative
			pow-exp		unary-exp [ ** pow-exp ]		// left associative
		
		unary-exp
			'-' unary-exp
			'!' unary-exp
			'~' unary-exp
			postfix-exp

		postfix-exp
			call-exp
			access-exp
			index-exp
			primary-exp

			call-exp
				postfix-exp '(' args-list ')'

			access-exp
				postfix-exp '.' identifier
		
			index-exp
				postfix-exp '[' exp ']'

		primary-exp
			literal
			identifier
			'(' exp ')'

		literal
			'null'
			'true'
			'false'
			literal-number
			literal-string
			literal-object
			literal-array
			literal-function
			

Types:
	scalarvalue types
		null:		null
		bool:		true, false
		int:		64 bit integer
		pointer:	32 or 64 bit opaque pointer for c/c++/(rust?) interop
		double		64 bit float
		string		utf8 string
					can do short string optimization
					can do interning for longer strings
		vector      2x or 3x or 4x
		matrix		{ 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1 }

	ref types
		array		[ 0, 1, 2, ... ]
		object		{ a = 1, b = 2, ... }
		function	fn (x, y, z) {} // closures are passed by-ref as well

Notes:
	objects will need some kind of 'prototype' or 'index' field to implement classes

	array is not just object in disguise, it can be implemented completely differently (fast indexing, no holes, etc)

	might do some operator overloading python or lua style

	function value could implement with pointer-to-code and pointer-to-closure
	for a class function we could use the "self" object as the closure
	for a free function the closure is the containing scope
	captured scopes will need to capture parent scopes as well (up to module or function boundary)
	so will need a linked list or something

	some syntax sugar:
		let f = fn (x, y) {}
		fn f(x, y) {}

	this is assumed to be running as part of a game engine
	so make sure the garbage collector can be done in parallel slices multi threaded and deterministic time limits

Notes:
	bits of double: 1 sign 11 exp 52 frac
	nan: exp==1, frac!=0
		we will set the top 16 bits to 1
		and use the bottom 48 for whatever
	inf: exp==1, frac==0
	zero:exp==0, frac==0
	nan happens when exp is all 1, frac is non-zero (sign bit ignored)
	quick and safe to set first 16 bits to 1, and use the remaining 48 bits for whatever

Notes:
	Exceptions / error handling

	The interpreter loop is stackless - maintains its own stack
	This means we don't need exceptions, longjmp, goto or anything
	too problematic for error handling. Instead we can just jump out of the interpreter loop
	to a defined error handler, maintain the program state and provide the option
	to jump back in.
	
	For example if C code calls a function and provides an error handler, if instruction N
	causes an error (eg trying to call a non-function) we can let the error handler
	decide whether to continue or not from instruction N+1
	(although it is likely the program continues to malfunction if the assumption is that instruction N was executed)
	eg:
		void foo() {
			tack_error_handler([](int error_code, const char* error_msg) -> int {
				if (error_code == MISSING_FILE) {
					return TACK_CONTINUE;
				} else{
					log("Unrecoverable error: ", error_msg);
					return TACK_EXIT;
				}
			})
			tack_execute(program) // throws a tack error
		}


Notes:
	Type analysis might be useful for optimization
	eg.
		let c = a + b
	what are the types of a and b? number, string, array, other?
	normally we need to emit typechecks when performing the add
	so we would have to treat the normal ADD instruction as possibly having any types
	however if the types of a and b are known, then we can emit a faster opcode that skips the checks
		ADD_ANY vs ADD_NUM, ADD_STR, ADD_ARRAY
	this also allows us to deduce the type of c, which can be used later in expressions involving c, etc etc
	
	so how to deduce the types? if assigned from literals, it's easy enough
		let a = 0
		let b = 1
		let greeting = "hello world"
		let foo = { ... }
	the ast can be walked and every expression can be type-deduced as much as possible.
	then when emitting code, we use the deduced type information

	if a function has no return sites, then the return type is null (?)
	otherwise it's the union of all the types of all the return sites.
	as every function has the implicit final return, it will be useful to elide this (as it adds null everywhere, which is not desirable)
	(It will be useful to mark dead code after a return statement, or maybe forbid it syntactically like lua does)
	This dead code removal can be used to elide the final implicit 'return null'
	(in fact, prioritize this as it's currently cluttering the bytecode)

	We can do some compile-time type checking for free at this point eg
		let a = fn() { return "foo" } let b = a() let c = 1 + b
	should be able to detect an error immediately without having to actually execute the code

	now once we have jitted the code (lol), the branch predictor will come to our aid
	for example a generic add looks like this: (pseudocode)
		if (type(a) == INT && type(b) == INT) {
			ADD_INT
		} else if (type(b) == STR && type(b) == STR) {

		} ... {
			...
		} else {
			error()
		}
	for any given function, it is likely to be used for one particular type 

	inline caching and monomorphization:
	call signature: the type resulting from the product of the argument types for a function call site
	prediction: most call signatures will be the same, with the odd change
	eg:
		f(1, 2, 3);		// CS = tuple<int,int,int>;
		f(1, 2, "foo"); // CS = tuple<int,int,string>;
		( For variadic functions/calls, the variadic part will be treated like an array,
		but perhaps is possible to monomorphize arrays as well?)
	MoMo: 
		emit different code for each call signature, and if possible use type deduction at the call site
		to decide which code to call
		inline caching: deciding the call at runtime as quickly as possible.

Notes:
	Functions vs closures vs "quasi-closures"

	A function would be a simple "pure-ish" function that takes some arguments, returns some value, and
	maybe has a few local variables. It does not close over variables from lexical higher scopes, so it would
	not constrain the lifetimes of any part of the lexical higher scopes.

	A closure would close over some of the variables in the LHS, so it will affect those variable's lifetimes.
	eg. 
		fn counter() {
			let i = 0
			fn inner() {
				i = i + 1
				return i
			}
			return inner
		}
	Because inner uses i from the outer scope, i must be boxed and ref-counted
	We will do this by generating an invisible tuple which contains all the captures (by reference)
	and is passed around with the function as a pair, participates in garbage collection, etc.
	Scalars which are captured in this manner must be auto-boxed.
	All the captures can be resolved at compile time, so even if there are captured variables from scopes that are multiple
	levels up, the reference that the closure uses is directly available in this invisible tuple

	There is a commonly occurring special case of closures that can be optimized however, which we can call "quasi-closures"
	This is the case of closure that uses variables from the parent scope, but itself is not used outside the parent scope
	eg. a function that is used as a sorting predicate

		fn quasi_closure_test() {
			let foo = 1
			
			// predicate() is a quasi-closure
			fn predicate() {
				// Capture a variable from the parent scope
				if foo {
					...
				}
			}

			// Use predicate in this function
			sorted_data = sort(some_data, predicate)
		}

	Because predicate is not used outside quasi_closure_test, we don't need to box any of the captures
	because the function lifetime is strictly shorter than the parent function, therefore everything that the child
	function needs to use should be found on the stack, and therefore should be accessible to the child function
	(It might need the parent scope's stack offset at runtime however, so some LOADs might become LOAD_WITH_OFFSET)
	We can use escape analysis to figure out whether the inner function escapes the outer function, and
	therefore whether it is a quasi-closure or not.

	Any named recursive function needs to capture itself so it can call itself.
	However what we are really doing is 
	